{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 빠르게 1차 데이터 전처리 방식대로 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기본 데이터 shape : (235413, 12)\n",
      "scale_pv < 5 shape : (233676, 12)\n",
      "E_scr_pv == 8 shape : (229983, 12)\n",
      "k_rpm_pv > 100 shape : (229810, 12)\n",
      "oct_data shape : (29651, 5)\n",
      "train_data shape : (200159, 5)\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing : 1st 분석 결과\n",
    "# - 05.27 수정 : 학습용 위해 2~4 미규제, E_scr_pv == 8, k_rpm_pv > 100 제거, 10월 기준 분리\n",
    "data = pd.read_csv('../DATA/raw_2023051820231018_경대기업맞춤형.csv')\n",
    "data.drop('Unnamed: 12', axis=1, inplace=True)  # Unnamed: 12 컬럼 제거\n",
    "print('기본 데이터 shape :', data.shape)\n",
    "# 1) 행 제거 (규제) \n",
    "# - 2 < scale_pv < 4 이외 데이터 제거 => 증강용으로 보류\n",
    "# - scale_pv < 5 만 남김\n",
    "# - E_scr_pv != 8 외 데이터 제거\n",
    "# - k_rpm_pv < 100 제거\n",
    "# data = data[(data['scale_pv'] > 2) & (data['scale_pv'] < 4)]\n",
    "data = data[data['scale_pv'] < 5]  # 약 1800개 제거\n",
    "print('scale_pv < 5 shape :', data.shape)\n",
    "data = data[data['E_scr_pv'] == 8]  # 약 3800개 제거\n",
    "print('E_scr_pv == 8 shape :', data.shape)\n",
    "data = data[data['k_rpm_pv'] > 100] # 약 170개 제거\n",
    "print('k_rpm_pv > 100 shape :', data.shape)\n",
    "\n",
    "# 2) 컬럼 제거\n",
    "# - E_scr_sv, c_temp_sv, n_temp_sv, s_temp_sv, k_rpm_sv, n_temp_sv 제거\n",
    "data.drop(['E_scr_sv', 'E_scr_pv', 'c_temp_sv', 's_temp_sv', 'k_rpm_sv', 'n_temp_sv'], axis=1, inplace=True)\n",
    "# data\n",
    "\n",
    "# 3) oct_data, train_data 분리\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "\n",
    "oct_data = data[data['time'].dt.month == 10]\n",
    "oct_data = oct_data.drop('time', axis=1)\n",
    "print('oct_data shape :', oct_data.shape)\n",
    "\n",
    "train_data = data[data['time'].dt.month != 10]\n",
    "train_data = train_data.drop('time', axis=1)\n",
    "print('train_data shape :', train_data.shape)\n",
    "\n",
    "# 4) 데이터 저장\n",
    "oct_data.to_csv('../DATA/oct_data.csv', index=False)\n",
    "train_data.to_csv('../DATA/train_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 증강 없이 학습 & 예측\n",
    "1. Oct_data : scale만 조정한 10월 데이터\n",
    "2. train_data : scale, k_rpm_pv만 조정한 10월 이전 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape : (36720, 5)\n",
      "oct_data shape : (1405, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    1405.000000\n",
       "mean        3.047580\n",
       "std         0.032548\n",
       "min         2.850000\n",
       "25%         3.030000\n",
       "50%         3.050000\n",
       "75%         3.060000\n",
       "max         3.280000\n",
       "Name: scale_pv, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 규제 : 2 < scale_pv < 4\n",
    "train_data = train_data[(train_data['scale_pv'] > 2) & (train_data['scale_pv'] < 4)]\n",
    "oct_data = oct_data[(oct_data['scale_pv'] > 2) & (oct_data['scale_pv'] < 4)]\n",
    "print('train_data shape :', train_data.shape)\n",
    "print('oct_data shape :', oct_data.shape)\n",
    "\n",
    "oct_data.scale_pv.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE : 0.020739688478127995\n",
      "MAPE : 0.6832850969599515\n",
      "R2 : 0.4061375618241577\n",
      "MAE : 0.027396616076884737\n",
      "MAPE : 0.8969436832994633\n",
      "R2 : -0.2623783404725153\n"
     ]
    }
   ],
   "source": [
    "# 증강 없이 학습\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "X = train_data.drop('scale_pv', axis=1)\n",
    "y = train_data['scale_pv']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200],\n",
    "#     'min_samples_split': [2, 5],\n",
    "#     'min_samples_leaf': [1, 2]\n",
    "# }\n",
    "# grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, n_jobs=-1, verbose=3, scoring='neg_mean_absolute_error')\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# print(grid_search.best_params_)\n",
    "\n",
    "# rf = grid_search.best_estimator_\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print('MAE :', mean_absolute_error(y_test, y_pred))\n",
    "print('MAPE :', mean_absolute_percentage_error(y_test, y_pred)*100)\n",
    "print('R2 :', r2_score(y_test, y_pred))\n",
    "\n",
    "# 증강 없이 예측\n",
    "X_oct = oct_data.drop('scale_pv', axis=1)\n",
    "y_oct = oct_data['scale_pv']\n",
    "y_oct_pred = rf.predict(X_oct)\n",
    "\n",
    "print('MAE :', mean_absolute_error(y_oct, y_oct_pred))\n",
    "print('MAPE :', mean_absolute_percentage_error(y_oct, y_oct_pred)*100)\n",
    "print('R2 :', r2_score(y_oct, y_oct_pred))\n",
    "\n",
    "# - rf에서 criterion='absolute_error'로 설정하면 너무 오래걸림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사실상 위 값은 피처 공학적 요소가 거의 없었다;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중공선성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시명님의 증강 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "# DF1 = data.copy()\n",
    "\n",
    "# DF1['time'] = pd.to_datetime(DF1['time'])\n",
    "\n",
    "# for idx, row in DF1.iterrows():\n",
    "#     if 2 <= row['scale_pv'] <= 4:\n",
    "#         target_time6 = row['time'] - timedelta(seconds=10)\n",
    "#         mask = (DF1['time'] <= row['time']) & (DF1['time'] >= target_time6)\n",
    "#         previous_rows = DF1[mask]\n",
    "        \n",
    "#         if len(previous_rows) > 1:\n",
    "#             previous_row = previous_rows.iloc[-2]  # 조건을 만족하는 가장 마지막에서 두 번째 행\n",
    "#             if previous_row['scale_pv'] <= 1:\n",
    "#                 # 조건을 만족하는 모든 행의 scale_pv 값을 패딩\n",
    "#                 for i in range(len(previous_rows)):\n",
    "#                     if previous_rows.iloc[i]['scale_pv'] <= 1:\n",
    "#                         DF1.loc[previous_rows.index[i], 'scale_pv'] = row['scale_pv']\n",
    "# DF1_2to4 = DF1[DF1.scale_pv.between(2,4)]\n",
    "# DF1_2to4\n",
    "\n",
    "# gpt가 수정 ================================\n",
    "# data = pd.read_csv('../DATA/raw_2023051820231018_경대기업맞춤형.csv')\n",
    "\n",
    "# DF1 = data.copy()\n",
    "# DF1['time'] = pd.to_datetime(DF1['time'])\n",
    "# DF1 = DF1.sort_values('time')  # 시간 순으로 정렬\n",
    "\n",
    "# # scale_pv가 2에서 4 사이인지 아닌지에 대한 boolean mask 생성\n",
    "# mask_2to4 = DF1['scale_pv'].between(2, 4)\n",
    "\n",
    "# # 10초 이내의 이전 행들 중 scale_pv가 1 이하인 행을 찾기 위한 mask 생성\n",
    "# mask_10s = (DF1['time'].values - DF1['time'].values[:, None]) <= np.timedelta64(10, 's')\n",
    "# mask_le1 = DF1['scale_pv'].values <= 1\n",
    "# mask_prev_le1 = np.tril(mask_10s & mask_le1)\n",
    "\n",
    "# # scale_pv가 2에서 4 사이인 행의 이전 행들 중 scale_pv가 1 이하인 행을 찾아서 업데이트\n",
    "# for idx in np.where(mask_2to4)[0]:\n",
    "#     prev_rows = np.where(mask_prev_le1[idx])[0]\n",
    "#     if len(prev_rows) > 0:\n",
    "#         DF1.loc[DF1.index[prev_rows], 'scale_pv'] = DF1.loc[DF1.index[idx], 'scale_pv']\n",
    "\n",
    "# DF1_2to4 = DF1[mask_2to4]\n",
    "# DF1_2to4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 진행\n",
    "# data_2to4, oct_data_2to4, train_data_2to4 = prep_1st(DF1_2to4)\n",
    "\n",
    "# print(data_2to4.shape, oct_data_2to4.shape, train_data_2to4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> 메모리 문제,,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN 개수 : 163440\n",
      "NaN 개수 : 163440\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     51\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m \u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAE :\u001b[39m\u001b[38;5;124m'\u001b[39m, mean_absolute_error(y_test, y_pred))\n",
      "File \u001b[1;32mc:\\Users\\HOME\\KDT5\\KDT5_Notes\\.conda\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HOME\\KDT5\\KDT5_Notes\\.conda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:348\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 348\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32mc:\\Users\\HOME\\KDT5\\KDT5_Notes\\.conda\\lib\\site-packages\\sklearn\\base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\HOME\\KDT5\\KDT5_Notes\\.conda\\lib\\site-packages\\sklearn\\utils\\validation.py:1162\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1144\u001b[0m     )\n\u001b[0;32m   1146\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1147\u001b[0m     X,\n\u001b[0;32m   1148\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1160\u001b[0m )\n\u001b[1;32m-> 1162\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1164\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\HOME\\KDT5\\KDT5_Notes\\.conda\\lib\\site-packages\\sklearn\\utils\\validation.py:1172\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[1;32m-> 1172\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1173\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1174\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1182\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[1;32mc:\\Users\\HOME\\KDT5\\KDT5_Notes\\.conda\\lib\\site-packages\\sklearn\\utils\\validation.py:957\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    951\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    952\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    953\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    954\u001b[0m         )\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 957\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    965\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Users\\HOME\\KDT5\\KDT5_Notes\\.conda\\lib\\site-packages\\sklearn\\utils\\validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HOME\\KDT5\\KDT5_Notes\\.conda\\lib\\site-packages\\sklearn\\utils\\validation.py:171\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    170\u001b[0m     )\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "# 증강하여 학습\n",
    "# - train_data의 1 미만인 값에서 KNN으로 증강\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "data = pd.read_csv('../DATA/raw_2023051820231018_경대기업맞춤형.csv')\n",
    "\n",
    "# 10월 이전 데이터만 사용\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "train_data = data[data['time'].dt.month != 10]\n",
    "oct_data = data[data['time'].dt.month == 10]\n",
    "\n",
    "# scale_pv < 4 데이터만 사용\n",
    "train_data = train_data[train_data['scale_pv'] < 4]\n",
    "\n",
    "# n_temp_sv == 0 제거\n",
    "train_data = train_data[train_data['n_temp_sv'] != 0]\n",
    "\n",
    "# 100 < k_rpm_pv\n",
    "train_data = train_data[train_data['k_rpm_pv'] > 100]\n",
    "\n",
    "# scale_pv < 2 => NaN\n",
    "train_data['scale_pv'] = train_data['scale_pv'].apply(lambda x: np.nan if x < 2 else x)\n",
    "print('NaN 개수 :', train_data['scale_pv'].isnull().sum())\n",
    "\n",
    "# drop columns\n",
    "train_data.drop(['Unnamed: 12', 'E_scr_sv', 'c_temp_sv', 'n_temp_sv', 's_temp_sv', 'k_rpm_sv', 'time'], axis=1, inplace=True)\n",
    "\n",
    "# KNN Imputer : target은 scale_pv, NaN은 2 미만인 값\n",
    "X = train_data.drop('scale_pv', axis=1)\n",
    "y = train_data['scale_pv']\n",
    "\n",
    "# scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# imputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "# y = imputer.fit_transform(y.values.reshape(-1, 1)).reshape(-1)\n",
    "print('NaN 개수 :', np.isnan(y).sum())\n",
    "\n",
    "# 증강된 데이터로 학습\n",
    "train_data['scale_pv'] = y\n",
    "\n",
    "X = train_data.drop('scale_pv', axis=1)\n",
    "y = train_data['scale_pv']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print('MAE :', mean_absolute_error(y_test, y_pred))\n",
    "print('MAPE :', mean_absolute_percentage_error(y_test, y_pred)*100)\n",
    "print('R2 :', r2_score(y_test, y_pred))\n",
    "\n",
    "# 증강된 데이터로 예측\n",
    "# - oct_data : 2 < scale_pv < 4\n",
    "oct_data = oct_data[(oct_data['scale_pv'] > 2) & (oct_data['scale_pv'] < 4)]\n",
    "oct_data.drop(['Unnamed: 12', 'E_scr_sv', 'c_temp_sv', 'n_temp_sv', 's_temp_sv', 'k_rpm_sv', 'time'], axis=1, inplace=True)\n",
    "\n",
    "X_oct = oct_data.drop('scale_pv', axis=1)\n",
    "y_oct = oct_data['scale_pv']\n",
    "y_oct_pred = rf.predict(X_oct)\n",
    "\n",
    "print('MAE :', mean_absolute_error(y_oct, y_oct_pred))\n",
    "print('MAPE :', mean_absolute_percentage_error(y_oct, y_oct_pred)*100)\n",
    "print('R2 :', r2_score(y_oct, y_oct_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN 증강에서 오류, 수정해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
